{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98add42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tools import dotdict\n",
    "from driver.driver import ABC_Driver\n",
    "# from torch_geometric_temporal import METRLADatasetLoader\n",
    "# from other_model.other_model import make_default_model\n",
    "# import atd2022\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456d00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_args = dotdict()\n",
    "\n",
    "cifar10_args.name = 'cifar10'\n",
    "cifar10_args.train_batch_size = 128\n",
    "cifar10_args.predict_batch_size = 128\n",
    "cifar10_args.device = ['cuda:1']\n",
    "\n",
    "cifar10_args.train_epochs = 250\n",
    "cifar10_args.lr = 0.01\n",
    "cifar10_args.criterion = 'CE'\n",
    "cifar10_args.optimizer = 'AdamW'\n",
    "cifar10_args.scheduler = 'OneCycle'\n",
    "cifar10_args.attack = {'fgsm':(0.005,), 'pgd':(0.005,0.1,20),'deepfool':(0.005,0.1,20),'apgd-ce':(0.005,)}\n",
    "\n",
    "activation = 'relu'\n",
    "input_channel = 3\n",
    "\n",
    "n=64\n",
    "knpp = [n,2*n,3*n,5*n,7*n,9*n,11*n,13*n,15*n,17*n,19*n,21*n]\n",
    "groups = n\n",
    "cifar10_args.layers=[\n",
    "    ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[4], knpp[5], (3,3), 1, 1, 1, groups), 2, 'first', (2,2), activation, False)),\n",
    "    ('cnn2d', ((knpp[5], knpp[6], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[6], knpp[7], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[7], knpp[8], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[8], knpp[9], (3,3), 1, 1, 1, groups), 2, 'first', (2,2), activation, False)),\n",
    "    ('cnn2d', ((knpp[9], knpp[10], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('cnn2d', ((knpp[10], knpp[11], (3,3), 1, 1, 1, groups), 2, None, None, activation, False)),\n",
    "    ('adptavgpool', (1,1)), \n",
    "    ('linear', (knpp[-1], 10, (1,2,3)))\n",
    "]\n",
    "\n",
    "# n=128\n",
    "# knpp = [n]*12\n",
    "# groups=n//2\n",
    "\n",
    "# cifar10_args.layers=[\n",
    "#     ('cnn2d', ((input_channel, knpp[0], (3,3), 1, 1, 1, 1), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[0], knpp[1], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[1], knpp[2], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[2], knpp[3], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[3], knpp[4], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[4], knpp[5], (3,3), 1, 1, 1, groups), 1, 'first', (2,2), activation, False)),\n",
    "#     ('atrc2d', ((knpp[5], knpp[6], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[6], knpp[7], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[7], knpp[8], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[8], knpp[9], (3,3), 1, 1, 1, groups), 1, 'first', (2,2), activation, False)),\n",
    "#     ('atrc2d', ((knpp[9], knpp[10], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('atrc2d', ((knpp[10], knpp[11], (3,3), 1, 1, 1, groups), 1, None, None, activation, False)),\n",
    "#     ('adptavgpool', (1,1)), \n",
    "#     ('linear', (knpp[-1], 10, (1,2,3)))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1924ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:1']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 05/09/2023 07:11\n",
      "epoch: 0, train_loss: 1.8318, test_metric: 0.4606, time: 47.216683864593506\n",
      "epoch: 1, train_loss: 1.5053, test_metric: 0.562, time: 45.64984750747681\n",
      "epoch: 2, train_loss: 1.3671, test_metric: 0.6028, time: 45.73778295516968\n",
      "epoch: 3, train_loss: 1.2922, test_metric: 0.6137, time: 45.6393678188324\n",
      "epoch: 4, train_loss: 1.2363, test_metric: 0.604, time: 45.319767475128174\n",
      "epoch: 5, train_loss: 1.2033, test_metric: 0.6551, time: 46.091941595077515\n",
      "epoch: 6, train_loss: 1.1655, test_metric: 0.6525, time: 45.92296242713928\n",
      "epoch: 7, train_loss: 1.1584, test_metric: 0.6487, time: 45.90433740615845\n",
      "epoch: 8, train_loss: 1.1455, test_metric: 0.6343, time: 45.9195613861084\n",
      "epoch: 9, train_loss: 1.1354, test_metric: 0.639, time: 45.621097564697266\n",
      "epoch: 10, train_loss: 1.1122, test_metric: 0.6428, time: 46.059338092803955\n",
      "epoch: 11, train_loss: 1.1136, test_metric: 0.6826, time: 45.78065729141235\n",
      "epoch: 12, train_loss: 1.1042, test_metric: 0.6992, time: 45.650885581970215\n",
      "epoch: 13, train_loss: 1.0988, test_metric: 0.6727, time: 45.86886811256409\n",
      "epoch: 14, train_loss: 1.1008, test_metric: 0.6927, time: 45.77800536155701\n",
      "epoch: 15, train_loss: 1.0879, test_metric: 0.6854, time: 45.724345207214355\n",
      "epoch: 16, train_loss: 1.0846, test_metric: 0.6688, time: 45.34237742424011\n",
      "epoch: 17, train_loss: 1.0728, test_metric: 0.6658, time: 45.25486087799072\n",
      "epoch: 18, train_loss: 1.085, test_metric: 0.6741, time: 45.285555601119995\n",
      "epoch: 19, train_loss: 1.0599, test_metric: 0.6881, time: 45.764602184295654\n",
      "epoch: 20, train_loss: 1.0643, test_metric: 0.7118, time: 45.665926456451416\n",
      "epoch: 21, train_loss: 1.0574, test_metric: 0.6936, time: 45.98720169067383\n",
      "epoch: 22, train_loss: 1.0407, test_metric: 0.6926, time: 45.26586365699768\n",
      "epoch: 23, train_loss: 1.0395, test_metric: 0.6585, time: 45.63583707809448\n",
      "epoch: 24, train_loss: 1.0284, test_metric: 0.7226, time: 45.27677798271179\n",
      "epoch: 25, train_loss: 1.016, test_metric: 0.6777, time: 46.22891068458557\n",
      "epoch: 26, train_loss: 1.0089, test_metric: 0.6818, time: 45.50473713874817\n",
      "epoch: 27, train_loss: 0.9969, test_metric: 0.6907, time: 45.4687876701355\n",
      "epoch: 28, train_loss: 0.9835, test_metric: 0.7427, time: 45.64886975288391\n",
      "epoch: 29, train_loss: 0.9818, test_metric: 0.7449, time: 45.557474851608276\n",
      "epoch: 30, train_loss: 0.9763, test_metric: 0.6882, time: 45.57166886329651\n",
      "epoch: 31, train_loss: 0.9579, test_metric: 0.7256, time: 45.08075428009033\n",
      "epoch: 32, train_loss: 0.9632, test_metric: 0.7474, time: 46.07987594604492\n",
      "epoch: 33, train_loss: 0.9535, test_metric: 0.7196, time: 45.81960344314575\n",
      "epoch: 34, train_loss: 0.9388, test_metric: 0.7043, time: 46.232205629348755\n",
      "epoch: 35, train_loss: 0.9368, test_metric: 0.7593, time: 45.34917712211609\n",
      "epoch: 36, train_loss: 0.9216, test_metric: 0.7442, time: 45.601017475128174\n",
      "epoch: 37, train_loss: 0.9135, test_metric: 0.708, time: 45.41726803779602\n",
      "epoch: 38, train_loss: 0.9053, test_metric: 0.7718, time: 45.42927169799805\n",
      "epoch: 39, train_loss: 0.8917, test_metric: 0.6907, time: 45.22370433807373\n",
      "epoch: 40, train_loss: 0.8858, test_metric: 0.6976, time: 45.49958896636963\n",
      "epoch: 41, train_loss: 0.881, test_metric: 0.7644, time: 45.70515751838684\n",
      "epoch: 42, train_loss: 0.8691, test_metric: 0.7572, time: 46.0640926361084\n",
      "epoch: 43, train_loss: 0.8677, test_metric: 0.7644, time: 45.52031183242798\n",
      "epoch: 44, train_loss: 0.8585, test_metric: 0.7668, time: 45.678303718566895\n",
      "epoch: 45, train_loss: 0.854, test_metric: 0.765, time: 45.44997310638428\n",
      "epoch: 46, train_loss: 0.8447, test_metric: 0.7861, time: 45.87650680541992\n",
      "epoch: 47, train_loss: 0.8479, test_metric: 0.7762, time: 45.90099835395813\n",
      "epoch: 48, train_loss: 0.8325, test_metric: 0.7586, time: 46.06744408607483\n",
      "epoch: 49, train_loss: 0.8377, test_metric: 0.7627, time: 46.09900450706482\n",
      "epoch: 50, train_loss: 0.8232, test_metric: 0.7813, time: 46.115636348724365\n",
      "epoch: 51, train_loss: 0.8168, test_metric: 0.7595, time: 45.4070827960968\n",
      "epoch: 52, train_loss: 0.8104, test_metric: 0.775, time: 45.19750165939331\n",
      "epoch: 53, train_loss: 0.8191, test_metric: 0.7915, time: 45.81491994857788\n",
      "epoch: 54, train_loss: 0.8026, test_metric: 0.7748, time: 45.98855948448181\n",
      "epoch: 55, train_loss: 0.7989, test_metric: 0.7177, time: 45.960219860076904\n",
      "epoch: 56, train_loss: 0.7992, test_metric: 0.7692, time: 45.820460081100464\n",
      "epoch: 57, train_loss: 0.7936, test_metric: 0.7839, time: 45.39502835273743\n",
      "epoch: 58, train_loss: 0.795, test_metric: 0.7951, time: 45.42289161682129\n",
      "epoch: 59, train_loss: 0.7848, test_metric: 0.7935, time: 45.41072368621826\n",
      "epoch: 60, train_loss: 0.7796, test_metric: 0.7806, time: 45.4590539932251\n",
      "epoch: 61, train_loss: 0.7791, test_metric: 0.7968, time: 45.93313479423523\n",
      "epoch: 62, train_loss: 0.7753, test_metric: 0.7894, time: 45.4735324382782\n",
      "epoch: 63, train_loss: 0.7682, test_metric: 0.7965, time: 45.98333263397217\n",
      "epoch: 64, train_loss: 0.7663, test_metric: 0.7933, time: 46.02719497680664\n",
      "epoch: 65, train_loss: 0.7576, test_metric: 0.7744, time: 45.41800618171692\n",
      "epoch: 66, train_loss: 0.7519, test_metric: 0.8122, time: 45.637657165527344\n",
      "epoch: 67, train_loss: 0.7519, test_metric: 0.7964, time: 45.71896767616272\n",
      "epoch: 68, train_loss: 0.7477, test_metric: 0.8076, time: 45.27177929878235\n",
      "epoch: 69, train_loss: 0.7416, test_metric: 0.8064, time: 45.92564630508423\n",
      "epoch: 70, train_loss: 0.7359, test_metric: 0.8015, time: 45.80500364303589\n",
      "epoch: 71, train_loss: 0.7361, test_metric: 0.8003, time: 45.94157576560974\n",
      "epoch: 72, train_loss: 0.7328, test_metric: 0.8162, time: 45.720338344573975\n",
      "epoch: 73, train_loss: 0.7308, test_metric: 0.8087, time: 46.00627827644348\n",
      "epoch: 74, train_loss: 0.7217, test_metric: 0.8221, time: 45.715986251831055\n",
      "epoch: 75, train_loss: 0.7236, test_metric: 0.805, time: 45.92258286476135\n",
      "epoch: 76, train_loss: 0.716, test_metric: 0.8097, time: 45.785701274871826\n",
      "epoch: 77, train_loss: 0.7129, test_metric: 0.8137, time: 45.30736470222473\n",
      "epoch: 78, train_loss: 0.7093, test_metric: 0.8217, time: 45.20065975189209\n",
      "epoch: 79, train_loss: 0.7077, test_metric: 0.787, time: 45.41609072685242\n",
      "epoch: 80, train_loss: 0.7038, test_metric: 0.8255, time: 45.41269564628601\n",
      "epoch: 81, train_loss: 0.6984, test_metric: 0.8073, time: 45.26475143432617\n",
      "epoch: 82, train_loss: 0.6952, test_metric: 0.8098, time: 45.57560062408447\n",
      "epoch: 83, train_loss: 0.6956, test_metric: 0.8156, time: 45.95743775367737\n",
      "epoch: 84, train_loss: 0.691, test_metric: 0.8087, time: 45.48875403404236\n",
      "epoch: 85, train_loss: 0.6828, test_metric: 0.81, time: 45.499022006988525\n",
      "epoch: 86, train_loss: 0.6813, test_metric: 0.8106, time: 45.49284338951111\n",
      "epoch: 87, train_loss: 0.6868, test_metric: 0.8233, time: 45.565677881240845\n",
      "epoch: 88, train_loss: 0.6711, test_metric: 0.7903, time: 45.9158251285553\n",
      "epoch: 89, train_loss: 0.6704, test_metric: 0.8269, time: 45.968459129333496\n",
      "epoch: 90, train_loss: 0.6711, test_metric: 0.8335, time: 46.35349225997925\n",
      "epoch: 91, train_loss: 0.6652, test_metric: 0.8309, time: 45.993236780166626\n",
      "epoch: 92, train_loss: 0.6702, test_metric: 0.8154, time: 45.861074447631836\n",
      "epoch: 93, train_loss: 0.6594, test_metric: 0.8238, time: 46.194212436676025\n",
      "epoch: 94, train_loss: 0.6517, test_metric: 0.8333, time: 46.00764799118042\n",
      "epoch: 95, train_loss: 0.653, test_metric: 0.83, time: 45.886616468429565\n",
      "epoch: 96, train_loss: 0.6514, test_metric: 0.8434, time: 46.11266231536865\n",
      "epoch: 97, train_loss: 0.6558, test_metric: 0.8194, time: 45.8347852230072\n",
      "epoch: 98, train_loss: 0.6459, test_metric: 0.8318, time: 45.50844478607178\n",
      "epoch: 99, train_loss: 0.649, test_metric: 0.8263, time: 45.81151103973389\n",
      "epoch: 100, train_loss: 0.6377, test_metric: 0.8132, time: 45.339595794677734\n",
      "epoch: 101, train_loss: 0.629, test_metric: 0.8318, time: 45.46250581741333\n",
      "epoch: 102, train_loss: 0.6367, test_metric: 0.8197, time: 45.531888008117676\n",
      "epoch: 103, train_loss: 0.6316, test_metric: 0.8446, time: 45.458762407302856\n",
      "epoch: 104, train_loss: 0.6255, test_metric: 0.8321, time: 45.78333020210266\n",
      "epoch: 105, train_loss: 0.6292, test_metric: 0.841, time: 45.646920919418335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106, train_loss: 0.6248, test_metric: 0.847, time: 45.85289192199707\n",
      "epoch: 107, train_loss: 0.6248, test_metric: 0.8396, time: 46.159345626831055\n",
      "epoch: 108, train_loss: 0.6168, test_metric: 0.8355, time: 45.84522199630737\n",
      "epoch: 109, train_loss: 0.6128, test_metric: 0.839, time: 46.19829702377319\n",
      "epoch: 110, train_loss: 0.6144, test_metric: 0.8468, time: 46.24088430404663\n",
      "epoch: 111, train_loss: 0.6165, test_metric: 0.8427, time: 45.8742835521698\n",
      "epoch: 112, train_loss: 0.6154, test_metric: 0.8421, time: 46.21524381637573\n",
      "epoch: 113, train_loss: 0.6037, test_metric: 0.8413, time: 46.223047733306885\n",
      "epoch: 114, train_loss: 0.6043, test_metric: 0.8461, time: 46.43198204040527\n",
      "epoch: 115, train_loss: 0.5991, test_metric: 0.8401, time: 45.76409697532654\n",
      "epoch: 116, train_loss: 0.5968, test_metric: 0.8478, time: 46.26546835899353\n",
      "epoch: 117, train_loss: 0.6015, test_metric: 0.8483, time: 45.406376361846924\n",
      "epoch: 118, train_loss: 0.5912, test_metric: 0.8454, time: 45.46627402305603\n",
      "epoch: 119, train_loss: 0.5881, test_metric: 0.8469, time: 45.24736022949219\n",
      "epoch: 120, train_loss: 0.5926, test_metric: 0.8357, time: 45.52283501625061\n",
      "epoch: 121, train_loss: 0.5885, test_metric: 0.8353, time: 45.968137979507446\n",
      "epoch: 122, train_loss: 0.5827, test_metric: 0.8518, time: 46.03421092033386\n",
      "epoch: 123, train_loss: 0.5868, test_metric: 0.8443, time: 45.748032331466675\n",
      "epoch: 124, train_loss: 0.5747, test_metric: 0.8501, time: 45.780213594436646\n",
      "epoch: 125, train_loss: 0.5714, test_metric: 0.8511, time: 45.748814821243286\n",
      "epoch: 126, train_loss: 0.575, test_metric: 0.8542, time: 45.5481162071228\n",
      "epoch: 127, train_loss: 0.5725, test_metric: 0.8512, time: 46.04663109779358\n",
      "epoch: 128, train_loss: 0.5712, test_metric: 0.8476, time: 45.889965772628784\n",
      "epoch: 129, train_loss: 0.5649, test_metric: 0.8354, time: 46.027804374694824\n",
      "epoch: 130, train_loss: 0.5643, test_metric: 0.8587, time: 46.05125093460083\n",
      "epoch: 131, train_loss: 0.5634, test_metric: 0.8448, time: 45.65682506561279\n",
      "epoch: 132, train_loss: 0.5608, test_metric: 0.8494, time: 45.904359579086304\n",
      "epoch: 133, train_loss: 0.5572, test_metric: 0.856, time: 45.88423776626587\n",
      "epoch: 134, train_loss: 0.562, test_metric: 0.8515, time: 45.708927392959595\n",
      "epoch: 135, train_loss: 0.5473, test_metric: 0.8587, time: 45.89749836921692\n",
      "epoch: 136, train_loss: 0.5518, test_metric: 0.8511, time: 45.69908571243286\n",
      "epoch: 137, train_loss: 0.5539, test_metric: 0.8463, time: 45.6047420501709\n",
      "epoch: 138, train_loss: 0.5465, test_metric: 0.8627, time: 45.21332383155823\n",
      "epoch: 139, train_loss: 0.5429, test_metric: 0.8539, time: 45.40700125694275\n",
      "epoch: 140, train_loss: 0.5386, test_metric: 0.8606, time: 45.342851877212524\n",
      "epoch: 141, train_loss: 0.5401, test_metric: 0.8546, time: 45.712339878082275\n",
      "epoch: 142, train_loss: 0.5329, test_metric: 0.8584, time: 45.89520049095154\n",
      "epoch: 143, train_loss: 0.5318, test_metric: 0.8614, time: 45.6716890335083\n",
      "epoch: 144, train_loss: 0.543, test_metric: 0.8527, time: 45.54376530647278\n",
      "epoch: 145, train_loss: 0.5315, test_metric: 0.8545, time: 45.54058480262756\n",
      "epoch: 146, train_loss: 0.5325, test_metric: 0.864, time: 45.3716778755188\n",
      "epoch: 147, train_loss: 0.5292, test_metric: 0.8619, time: 45.3315749168396\n",
      "epoch: 148, train_loss: 0.5237, test_metric: 0.87, time: 45.711994886398315\n",
      "epoch: 149, train_loss: 0.5243, test_metric: 0.862, time: 45.458219051361084\n",
      "epoch: 150, train_loss: 0.518, test_metric: 0.8585, time: 45.74511528015137\n",
      "epoch: 151, train_loss: 0.5189, test_metric: 0.8626, time: 45.65082097053528\n",
      "epoch: 152, train_loss: 0.519, test_metric: 0.858, time: 45.90192699432373\n",
      "epoch: 153, train_loss: 0.5161, test_metric: 0.86, time: 45.470359802246094\n",
      "epoch: 154, train_loss: 0.5145, test_metric: 0.8666, time: 45.430668354034424\n",
      "epoch: 155, train_loss: 0.5101, test_metric: 0.8607, time: 45.749725580215454\n",
      "epoch: 156, train_loss: 0.509, test_metric: 0.8593, time: 45.70890140533447\n",
      "epoch: 157, train_loss: 0.5049, test_metric: 0.8632, time: 45.79305076599121\n",
      "epoch: 158, train_loss: 0.5036, test_metric: 0.8632, time: 45.88809084892273\n",
      "epoch: 159, train_loss: 0.5014, test_metric: 0.8581, time: 45.331496477127075\n",
      "epoch: 160, train_loss: 0.5015, test_metric: 0.8657, time: 45.194247007369995\n",
      "epoch: 161, train_loss: 0.4926, test_metric: 0.8718, time: 45.581894397735596\n",
      "epoch: 162, train_loss: 0.5013, test_metric: 0.8638, time: 45.686110496520996\n",
      "epoch: 163, train_loss: 0.4982, test_metric: 0.8695, time: 45.42547416687012\n",
      "epoch: 164, train_loss: 0.4923, test_metric: 0.8733, time: 45.53792977333069\n",
      "epoch: 165, train_loss: 0.4881, test_metric: 0.8645, time: 45.48305535316467\n",
      "epoch: 166, train_loss: 0.4942, test_metric: 0.8674, time: 45.41389751434326\n",
      "epoch: 167, train_loss: 0.4885, test_metric: 0.8743, time: 45.68614149093628\n",
      "epoch: 168, train_loss: 0.4844, test_metric: 0.8746, time: 45.6092004776001\n",
      "epoch: 169, train_loss: 0.4868, test_metric: 0.8702, time: 45.77224898338318\n",
      "epoch: 170, train_loss: 0.4772, test_metric: 0.8714, time: 45.162906885147095\n",
      "epoch: 171, train_loss: 0.4695, test_metric: 0.8645, time: 45.67486047744751\n",
      "epoch: 172, train_loss: 0.4695, test_metric: 0.8727, time: 45.277663707733154\n",
      "epoch: 173, train_loss: 0.467, test_metric: 0.8703, time: 45.16352653503418\n",
      "epoch: 174, train_loss: 0.4693, test_metric: 0.8753, time: 45.597851037979126\n",
      "epoch: 175, train_loss: 0.4707, test_metric: 0.8754, time: 46.23422694206238\n",
      "epoch: 176, train_loss: 0.4599, test_metric: 0.8762, time: 46.0038697719574\n",
      "epoch: 177, train_loss: 0.4691, test_metric: 0.8737, time: 45.71593236923218\n",
      "epoch: 178, train_loss: 0.4669, test_metric: 0.8804, time: 45.88069534301758\n",
      "epoch: 179, train_loss: 0.4627, test_metric: 0.8802, time: 45.348652601242065\n",
      "epoch: 180, train_loss: 0.4534, test_metric: 0.8758, time: 45.44622588157654\n",
      "epoch: 181, train_loss: 0.4602, test_metric: 0.8844, time: 45.28487420082092\n",
      "epoch: 182, train_loss: 0.4518, test_metric: 0.8799, time: 45.09222745895386\n",
      "epoch: 183, train_loss: 0.4526, test_metric: 0.8818, time: 45.396520376205444\n",
      "epoch: 184, train_loss: 0.4515, test_metric: 0.8784, time: 45.60964775085449\n",
      "epoch: 185, train_loss: 0.4565, test_metric: 0.8767, time: 45.734121799468994\n",
      "epoch: 186, train_loss: 0.4526, test_metric: 0.8809, time: 45.782286405563354\n",
      "epoch: 187, train_loss: 0.45, test_metric: 0.8836, time: 45.53787398338318\n",
      "epoch: 188, train_loss: 0.4426, test_metric: 0.8787, time: 45.803645610809326\n",
      "epoch: 189, train_loss: 0.4366, test_metric: 0.8825, time: 45.61389493942261\n",
      "epoch: 190, train_loss: 0.4398, test_metric: 0.8796, time: 45.65026307106018\n",
      "epoch: 191, train_loss: 0.4423, test_metric: 0.8778, time: 45.946089029312134\n",
      "epoch: 192, train_loss: 0.434, test_metric: 0.8856, time: 46.10073471069336\n",
      "epoch: 193, train_loss: 0.4396, test_metric: 0.8822, time: 46.02197217941284\n",
      "epoch: 194, train_loss: 0.4341, test_metric: 0.8817, time: 45.782644748687744\n",
      "epoch: 195, train_loss: 0.4355, test_metric: 0.8844, time: 46.47361779212952\n",
      "epoch: 196, train_loss: 0.4346, test_metric: 0.8822, time: 46.13464570045471\n",
      "epoch: 197, train_loss: 0.4244, test_metric: 0.885, time: 46.05553603172302\n",
      "epoch: 198, train_loss: 0.4305, test_metric: 0.8846, time: 46.13133001327515\n",
      "epoch: 199, train_loss: 0.4265, test_metric: 0.8834, time: 46.0167076587677\n",
      "epoch: 200, train_loss: 0.4249, test_metric: 0.8834, time: 45.429118156433105\n",
      "epoch: 201, train_loss: 0.4227, test_metric: 0.8867, time: 45.21016263961792\n",
      "epoch: 202, train_loss: 0.4186, test_metric: 0.8852, time: 45.354443073272705\n",
      "epoch: 203, train_loss: 0.4143, test_metric: 0.8852, time: 45.77261447906494\n",
      "epoch: 204, train_loss: 0.4179, test_metric: 0.8847, time: 45.989540100097656\n",
      "epoch: 205, train_loss: 0.4187, test_metric: 0.8829, time: 45.4740526676178\n",
      "epoch: 206, train_loss: 0.4167, test_metric: 0.8824, time: 45.361491680145264\n",
      "epoch: 207, train_loss: 0.4135, test_metric: 0.8836, time: 45.57424259185791\n",
      "epoch: 208, train_loss: 0.4118, test_metric: 0.8839, time: 45.53425168991089\n",
      "epoch: 209, train_loss: 0.4117, test_metric: 0.8836, time: 45.7031455039978\n",
      "epoch: 210, train_loss: 0.4115, test_metric: 0.8882, time: 45.75287485122681\n",
      "epoch: 211, train_loss: 0.408, test_metric: 0.8839, time: 45.547067165374756\n",
      "epoch: 212, train_loss: 0.409, test_metric: 0.8889, time: 45.71411371231079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 213, train_loss: 0.4041, test_metric: 0.8869, time: 45.95288562774658\n",
      "epoch: 214, train_loss: 0.4009, test_metric: 0.8895, time: 45.44904613494873\n",
      "epoch: 215, train_loss: 0.4032, test_metric: 0.8864, time: 45.493107080459595\n",
      "epoch: 216, train_loss: 0.4067, test_metric: 0.8877, time: 45.569013595581055\n",
      "epoch: 217, train_loss: 0.403, test_metric: 0.8874, time: 45.88287949562073\n",
      "epoch: 218, train_loss: 0.3974, test_metric: 0.8893, time: 45.44049525260925\n",
      "epoch: 219, train_loss: 0.3988, test_metric: 0.8869, time: 46.090885639190674\n",
      "epoch: 220, train_loss: 0.3956, test_metric: 0.8873, time: 45.565025329589844\n",
      "epoch: 221, train_loss: 0.3994, test_metric: 0.8884, time: 45.602678060531616\n",
      "epoch: 222, train_loss: 0.3948, test_metric: 0.8894, time: 45.582011222839355\n",
      "epoch: 223, train_loss: 0.3985, test_metric: 0.89, time: 45.28463315963745\n",
      "epoch: 224, train_loss: 0.3933, test_metric: 0.8881, time: 45.517457485198975\n",
      "epoch: 225, train_loss: 0.3894, test_metric: 0.8905, time: 45.48804211616516\n",
      "epoch: 226, train_loss: 0.3964, test_metric: 0.8896, time: 46.04538011550903\n",
      "epoch: 227, train_loss: 0.3905, test_metric: 0.8885, time: 46.00816249847412\n",
      "epoch: 228, train_loss: 0.3892, test_metric: 0.8893, time: 45.64662837982178\n",
      "epoch: 229, train_loss: 0.3923, test_metric: 0.8912, time: 45.32015323638916\n",
      "epoch: 230, train_loss: 0.3879, test_metric: 0.8887, time: 45.631821393966675\n",
      "epoch: 231, train_loss: 0.3879, test_metric: 0.8897, time: 45.62247037887573\n",
      "epoch: 232, train_loss: 0.3897, test_metric: 0.8882, time: 45.55784845352173\n",
      "epoch: 233, train_loss: 0.3915, test_metric: 0.8917, time: 45.65700554847717\n",
      "epoch: 234, train_loss: 0.3881, test_metric: 0.8896, time: 45.52574396133423\n",
      "epoch: 235, train_loss: 0.3918, test_metric: 0.8928, time: 45.887109994888306\n",
      "epoch: 236, train_loss: 0.3866, test_metric: 0.8892, time: 45.91511273384094\n",
      "epoch: 237, train_loss: 0.3943, test_metric: 0.89, time: 45.37270927429199\n",
      "epoch: 238, train_loss: 0.3816, test_metric: 0.8913, time: 45.405009269714355\n",
      "epoch: 239, train_loss: 0.388, test_metric: 0.8905, time: 45.86744546890259\n",
      "epoch: 240, train_loss: 0.3871, test_metric: 0.8895, time: 45.88519811630249\n",
      "epoch: 241, train_loss: 0.3872, test_metric: 0.8913, time: 45.59934639930725\n",
      "epoch: 242, train_loss: 0.3847, test_metric: 0.888, time: 45.39439415931702\n",
      "epoch: 243, train_loss: 0.3858, test_metric: 0.8888, time: 45.44263792037964\n",
      "epoch: 244, train_loss: 0.3867, test_metric: 0.8902, time: 45.43583536148071\n",
      "epoch: 245, train_loss: 0.3858, test_metric: 0.8912, time: 45.757827281951904\n",
      "epoch: 246, train_loss: 0.3874, test_metric: 0.8899, time: 45.76384878158569\n",
      "epoch: 247, train_loss: 0.3871, test_metric: 0.8906, time: 46.183923959732056\n",
      "epoch: 248, train_loss: 0.3906, test_metric: 0.8879, time: 45.75637936592102\n",
      "epoch: 249, train_loss: 0.3886, test_metric: 0.8894, time: 45.72108459472656\n",
      "fgsm 0.3088000416755676\n",
      "pgd 0.04520004987716675\n",
      "deepfool 0.12150001525878906\n",
      "setting parameters for standard version\n",
      "using standard version including apgd-ce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fsuser/Attention_based_CNN/Mark_Exp/attack/attack.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = torch.tensor(self.data_loader.origin_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy: 88.94%\n",
      "apgd-ce - 1/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 2/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 3/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 4/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 5/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 6/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 7/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 8/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 9/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 10/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 11/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 12/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 13/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 14/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 15/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 16/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 17/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 18/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 19/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 20/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 21/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 22/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 23/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 24/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 25/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 26/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 27/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 28/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 29/89 - 94 out of 100 successfully perturbed\n",
      "apgd-ce - 30/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 31/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 32/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 33/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 34/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 35/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 36/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 37/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 38/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 39/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 40/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 41/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 42/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 43/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 44/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 45/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 46/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 47/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 48/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 49/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 50/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 51/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 52/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 53/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 54/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 55/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 56/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 57/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 58/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 59/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 60/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 61/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 62/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 63/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 64/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 65/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 66/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 67/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 68/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 69/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 70/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 71/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 72/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 73/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 74/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 75/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 76/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 77/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 78/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 79/89 - 100 out of 100 successfully perturbed\n",
      "apgd-ce - 80/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 81/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 82/89 - 98 out of 100 successfully perturbed\n",
      "apgd-ce - 83/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 84/89 - 96 out of 100 successfully perturbed\n",
      "apgd-ce - 85/89 - 95 out of 100 successfully perturbed\n",
      "apgd-ce - 86/89 - 93 out of 100 successfully perturbed\n",
      "apgd-ce - 87/89 - 97 out of 100 successfully perturbed\n",
      "apgd-ce - 88/89 - 99 out of 100 successfully perturbed\n",
      "apgd-ce - 89/89 - 93 out of 94 successfully perturbed\n",
      "robust accuracy after APGD-CE: 1.94% (total time 501.2 s)\n",
      "max Linf perturbation: 0.00500, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 1.94%\n",
      "apgd-ce 0.0194\n",
      "clean       0.8894\n",
      "fgsm        0.3088\n",
      "pgd         0.0452\n",
      "deepfool    0.1215\n",
      "apgd-ce     0.0194\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_199965/216463784.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mABC_Driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar10_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Attention_based_CNN/Mark_Exp/driver/driver.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler_step_after_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_train_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_test_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_attack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Attention_based_CNN/Mark_Exp/record/record.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, outcome)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_test_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "driver = ABC_Driver(cifar10_args, None, record_path=None, if_hash=False)\n",
    "driver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ace77",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('cnn2d', ((3, 48, (3, 3), 1, 1, 1, 1), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((48, 96, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((96, 144, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((144, 240, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((240, 336, (3, 3), 1, 1, 1, 48), 1, 'first', (2, 2), 'relu', False)), \n",
    " ('atrc2d', ((336, 432, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((432, 528, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((528, 624, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((624, 720, (3, 3), 1, 1, 1, 48), 1, 'first', (2, 2), 'relu', False)), \n",
    " ('atrc2d', ((720, 816, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((816, 912, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('adptavgpool', (1, 1)), \n",
    " ('linear', (912, 10, (1, 2, 3)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('cnn2d', ((3, 48, (3, 3), 1, 1, 1, 1), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((48, 96, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((96, 144, (3, 3), 1, 1, 1, 48), 1, 'first', (2, 2), 'relu', False)), \n",
    " ('atrc2d', ((144, 240, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((240, 336, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((336, 432, (3, 3), 1, 1, 1, 48), 1, 'first', (2, 2), 'relu', False)), \n",
    " ('atrc2d', ((432, 528, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('atrc2d', ((528, 624, (3, 3), 1, 1, 1, 48), 1, None, None, 'relu', False)), \n",
    " ('adptavgpool', (1, 1)), \n",
    " ('linear', (624, 10, (1, 2, 3)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d0878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c70346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62679d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd92eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525a6459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(driver.model.state_dict(), \"save/CIFAR10_ARC_2023_05_08.pt\")\n",
    "# driver.model.load_state_dict(torch.load(\"save/CIFAR10_ARC_2023_05_08.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2671c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in driver.model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a605af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2088908"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d373267",
   "metadata": {},
   "outputs": [],
   "source": [
    "77+79+81+75+78+81+85+76+80+81+80+75+82+72+79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ac2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5938\n",
    "0.2799\n",
    "0.3814\n",
    "0.2126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8e307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a871c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf5bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5138b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e06214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90258f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c908b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: ['cuda:0', 'cuda:1']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add record: 05/05/2023 15:30\n",
      "epoch: 0, train_loss: 1.7397, test_metric: 0.5767, time: 1080.9909834861755\n",
      "epoch: 1, train_loss: 1.3245, test_metric: 0.6767, time: 1077.1897094249725\n",
      "epoch: 2, train_loss: 1.105, test_metric: 0.7434, time: 1077.46044921875\n",
      "epoch: 3, train_loss: 0.9854, test_metric: 0.7775, time: 1077.1588928699493\n",
      "epoch: 4, train_loss: 0.9099, test_metric: 0.7748, time: 1077.9000310897827\n",
      "epoch: 5, train_loss: 0.8371, test_metric: 0.7978, time: 1078.39155626297\n",
      "epoch: 6, train_loss: 0.7881, test_metric: 0.8227, time: 1078.2085292339325\n",
      "epoch: 7, train_loss: 0.7531, test_metric: 0.8237, time: 1078.0095698833466\n",
      "epoch: 8, train_loss: 0.7216, test_metric: 0.8276, time: 1077.7559113502502\n",
      "epoch: 9, train_loss: 0.7034, test_metric: 0.841, time: 1078.012107372284\n",
      "epoch: 10, train_loss: 0.6706, test_metric: 0.8532, time: 1077.6384491920471\n",
      "epoch: 11, train_loss: 0.6631, test_metric: 0.8424, time: 1077.6310753822327\n",
      "epoch: 12, train_loss: 0.6463, test_metric: 0.8466, time: 1078.4614560604095\n",
      "epoch: 13, train_loss: 0.6369, test_metric: 0.838, time: 1077.928382396698\n",
      "epoch: 14, train_loss: 0.6212, test_metric: 0.8579, time: 1078.7539024353027\n",
      "epoch: 15, train_loss: 0.6098, test_metric: 0.8631, time: 1077.7446601390839\n",
      "epoch: 16, train_loss: 0.5872, test_metric: 0.8554, time: 1078.1447839736938\n",
      "epoch: 17, train_loss: 0.5846, test_metric: 0.864, time: 1079.3174078464508\n",
      "epoch: 18, train_loss: 0.5791, test_metric: 0.8569, time: 1078.0331797599792\n",
      "epoch: 19, train_loss: 0.5676, test_metric: 0.8755, time: 1077.7556674480438\n",
      "epoch: 20, train_loss: 0.5587, test_metric: 0.8623, time: 1077.7824697494507\n",
      "epoch: 21, train_loss: 0.5407, test_metric: 0.8672, time: 1078.1265258789062\n",
      "epoch: 22, train_loss: 0.5322, test_metric: 0.8711, time: 1078.3362731933594\n",
      "epoch: 23, train_loss: 0.5141, test_metric: 0.8641, time: 1078.0959677696228\n",
      "epoch: 24, train_loss: 0.5056, test_metric: 0.8815, time: 1077.9647016525269\n",
      "epoch: 25, train_loss: 0.4904, test_metric: 0.8903, time: 1077.6193339824677\n",
      "epoch: 26, train_loss: 0.4807, test_metric: 0.9039, time: 1077.9664061069489\n",
      "epoch: 27, train_loss: 0.4717, test_metric: 0.8973, time: 1077.7508926391602\n",
      "epoch: 28, train_loss: 0.4475, test_metric: 0.8766, time: 1077.8302006721497\n",
      "epoch: 29, train_loss: 0.4319, test_metric: 0.9043, time: 1078.1162836551666\n",
      "epoch: 30, train_loss: 0.4122, test_metric: 0.9034, time: 1077.6427755355835\n",
      "epoch: 31, train_loss: 0.3963, test_metric: 0.8897, time: 1077.45272731781\n",
      "epoch: 32, train_loss: 0.3799, test_metric: 0.9115, time: 1077.7940783500671\n",
      "epoch: 33, train_loss: 0.3724, test_metric: 0.9085, time: 1077.7711226940155\n",
      "epoch: 34, train_loss: 0.3511, test_metric: 0.9136, time: 1078.3761348724365\n",
      "epoch: 35, train_loss: 0.3442, test_metric: 0.9101, time: 1077.7130739688873\n",
      "epoch: 36, train_loss: 0.3322, test_metric: 0.9228, time: 1077.7052483558655\n",
      "epoch: 37, train_loss: 0.323, test_metric: 0.8987, time: 1077.9627931118011\n",
      "epoch: 38, train_loss: 0.3117, test_metric: 0.9153, time: 1078.0134029388428\n",
      "epoch: 39, train_loss: 0.304, test_metric: 0.9208, time: 1078.5459139347076\n",
      "epoch: 40, train_loss: 0.291, test_metric: 0.9265, time: 1077.5876595973969\n",
      "epoch: 41, train_loss: 0.2853, test_metric: 0.9308, time: 1077.665192604065\n",
      "epoch: 42, train_loss: 0.2717, test_metric: 0.9274, time: 1078.1044027805328\n",
      "epoch: 43, train_loss: 0.2724, test_metric: 0.9272, time: 1077.8279221057892\n",
      "epoch: 44, train_loss: 0.2663, test_metric: 0.9193, time: 1077.6943764686584\n"
     ]
    }
   ],
   "source": [
    "driver = ABC_Driver(cifar10_args, None, record_path=None, if_hash=False)\n",
    "driver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
